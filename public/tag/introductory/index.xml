<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>introductory | Dylan&#39;s Blog</title>
    <link>/tag/introductory/</link>
      <atom:link href="/tag/introductory/index.xml" rel="self" type="application/rss+xml" />
    <description>introductory</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Wed, 27 May 2020 00:00:00 +0000</lastBuildDate>
    <image>
      <url>/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_2.png</url>
      <title>introductory</title>
      <link>/tag/introductory/</link>
    </image>
    
    <item>
      <title>The Perils of Overly Local Optimization</title>
      <link>/post/local-optimization/</link>
      <pubDate>Wed, 27 May 2020 00:00:00 +0000</pubDate>
      <guid>/post/local-optimization/</guid>
      <description>


&lt;p&gt;WORK IN PROGRESS, scattered notes/plots here visualized, will be turned into proper post soon. Aims to explain in layman’s terms the way that the addition of noise can help gradient descent escape spurious optima (and how this has an intuitive interpretation in our own lives)&lt;/p&gt;
&lt;div id=&#34;outline&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Outline&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Note, this was openly inspired by the writings of Tim Harford. I ound his descriptiption of the London Tube Strike and its implications while struggling through the study of Langevin diffusions, and I had been meaning to try and show some visualizations of noisy optimization for a while. He’s a wonderful popular economics communicator, and a lot of fun to read.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;In general, try and think of any and all images you can include! minimize text.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;the-perfect-scrambled-eggs&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;The Perfect Scrambled Eggs&lt;/h1&gt;
&lt;p&gt;(or “our optimized lives”)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;[rw]My morning routine is perfectly optimized, a blend of art and science. I’ve settled on an order in which to take the ingredients for scrambled eggs, the exact selection of dishes to use to minimize washing, and the fact that my silver bowl has sides just low enough that beaten egg could escape, and that raw eggs go in the red bowl. I didn’t set out to figure this out, I just made scrambled eggs every morning for years, and over time saw tiny choices that make it go a little smoother.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;To add…&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;disruption-and-the-london-subway-strike&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Disruption, and the London Subway Strike&lt;/h1&gt;
&lt;p&gt;On February 4th, 2014, the workers of the London Tube (their underground subway), went on strike, forcing a number of station closures throughout the city. For three days, a subset of commuters found their usual routes to work blocked, and were forced to find alternatives. After the strike, the stations reopened, and life went back to normal.&lt;/p&gt;
&lt;p&gt;But three economists saw the opportunity for a natural experiment: only certain commuters were disrupted by the closure, and using the tracking data collected by the Tube, their movements could be compared to the unaffected group. And surprisingly, life &lt;em&gt;didn’t&lt;/em&gt; go right back to normal after the ending of the strike. The ID card data showed that some of the impacted group stuck with their newly discovered routes, and their commuting time decreased as a result.&lt;/p&gt;
&lt;p&gt;The station closures forced commuters to break from their finely tuned routines, but a surprising number found themselves dragged unnwillingly along a route that proved faster than the one they had been taking for years. The economists even claim that on net, the strike decreased the total commuting time.&lt;a href=&#34;#fn1&#34; class=&#34;footnote-ref&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt; Even if only a small fraction found new routes, their new route would benefit them for years to come, and taking this chance only required disruption for a couple of days.&lt;/p&gt;
&lt;p&gt;This story provides a neat way to frame the mathematical challenge of optimization, and in particular, why so many optimization algorithms involve &lt;em&gt;random noise&lt;/em&gt;, a choice which initially seems bizarre. I’ll begin by describing how to think about optimization in intuitive terms, and then detail how that corresponds with the common mathematical algorithms, and why the London Tube Strike provides a neat analogy to very real mathematical properties.&lt;a href=&#34;#fn2&#34; class=&#34;footnote-ref&#34; id=&#34;fnref2&#34;&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;the-mathematical-framework-of-optimization&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;The Mathematical Framework of Optimization&lt;/h1&gt;
&lt;!-- This is duplicate with above? --&gt;
&lt;p&gt;The purpose of this post is to show how this concept can be naturally articulated in a mathematical framework.&lt;a href=&#34;#fn3&#34; class=&#34;footnote-ref&#34; id=&#34;fnref3&#34;&gt;&lt;sup&gt;3&lt;/sup&gt;&lt;/a&gt; We are describing the challenge of optimization. Here’s a sample definition, from the &lt;a href=&#34;https://deepai.org/machine-learning-glossary-and-terms/mathematical-optimization&#34;&gt;DeepAI website&lt;/a&gt;.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Mathematical optimization is the process of maximizing or minimizing an objective function by finding the best available values across a set of inputs.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;For London commuters, their “objective function” might be the duration of the commute,&lt;a href=&#34;#fn4&#34; class=&#34;footnote-ref&#34; id=&#34;fnref4&#34;&gt;&lt;sup&gt;4&lt;/sup&gt;&lt;/a&gt;, and the “available values across a set of inputs” might be the route they take.&lt;/li&gt;
&lt;li&gt;If we want to find the highest peak in a mountain range (an example we’ll discuss in detail in the next section), the input might be the choice of latitude and longitude, and the objective the elevation at that point.&lt;/li&gt;
&lt;li&gt;When baking chocolate chip cookies, the possible inputs might be the amount of each ingredient, and the order in which they are combined, and the objective function might be the tastiness of the resulting cookie. This isn’t quite a joke, Google once ran a &lt;a href=&#34;https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/46507.pdf&#34;&gt;cookie optimization experiment&lt;/a&gt; along these lines.&lt;a href=&#34;#fn5&#34; class=&#34;footnote-ref&#34; id=&#34;fnref5&#34;&gt;&lt;sup&gt;5&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Optimization is vitally important in applied mathematics and statistics, but it can be quite hard. The vast increase in computational power has broadened our horizons for what optimization challenges are possible, but many useful problems remain out of our reach.&lt;/p&gt;
&lt;p&gt;Generally, in optimization, we assume that we can check the value of the objective function at some chosen input. We can try a certain route on the subway and time the duration, we can bake a batch of cookies and eat them, and we will imagine that we have some computer which takes in latitude and longitude coordinates and spits out the altitude (this is called a “query” to the objective function, or perhaps “oracle”).&lt;/p&gt;
&lt;p&gt;Our naive optimization strategy might be to just try a bunch of points. Maybe we can define a grid of latitude and longitude coordinates, check the elevation of each one, and pick the highest. But this naive approach only works when the potential choices of input are sufficiently narrow. In particular, we look at the “dimension” of the input space. Latitude and longitude represent a mere 2-dimensions. The number of points within an exhaustive “grid” of inputs grows exponentially with the dimension of the input. Cookies are comprised by some dozen ingredients. The famous Jacques Torres &lt;a href=&#34;https://cooking.nytimes.com/recipes/1015819-chocolate-chip-cookies&#34;&gt;cookie recipe&lt;/a&gt; has &lt;span class=&#34;math inline&#34;&gt;\(12\)&lt;/span&gt; ingredients. If we wanted to try all combinations of a mere five levels of each ingredient, that would be over two hundred thousand possibilities, which is a bit much for even the hungriest baker.&lt;/p&gt;
&lt;p&gt;We are constantly confronting optimization challenges in our own life, and we rarely take this naive approach. Instead, we tend to look for small &lt;em&gt;local&lt;/em&gt; optimizations, whose benefits we can easily identify.&lt;/p&gt;
&lt;!-- * Finding the best route on the subway is something we optimize. While often algorithmic services can do the work for us, in other cases (or the past), we have to figure it out ourselves, and we somehow pick our starting point. --&gt;
&lt;!-- * For an example, let&#39;s imagine we want to find the highest point in a mountain range. We can check an individual point, and see how high it is. How do we find the highest point? The analogy would be something like, instead of latitude and longitude in a mountain range, in our morning routine it would be that &#34;series of choices for how we get to work&#34;.  --&gt;
&lt;!-- * Now, imagine instead of querying a computer for the height, you yourself were actually in that mountain range. What would you do? Well, you&#39;d look for the peak, but what if you were in a forest? You&#39;d go up. Specifically, you would look at the area around you for *local* guidance. --&gt;
&lt;/div&gt;
&lt;div id=&#34;locality-in-optimization&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Locality in Optimization&lt;/h1&gt;
&lt;p&gt;Imagine if we bite into a warm cookie, and the text the texture is just right, but there’s not enough chocolate.(more flowery language here?) We wouldn’t just throw up our hands and start from scratch… we’d add more chocolate! It’s hard to look at a cookie recipe, and imagine what the result will taste like. But we &lt;em&gt;can&lt;/em&gt; taste a recipe, and imagine what a small tweak would taste like.&lt;/p&gt;
&lt;p&gt;The “locality” in optimization refers to “closeness” in the input space. In latitude and longitude, this would be literal distance, while the definitions are a bit less cookie in the space of cookie ingredients and subway commutes. Broadly, we are pretty good at understanding. If we increase the amount of chocolate, we now they’ll taste a bit more chocolate-y than they do now. If we increase the amounts of chocolate, butter, baking soda, reduce the amount of flour, and tweak the balance between brown and cane sugar, are we confident we know what the result will taste like?&lt;/p&gt;
&lt;p&gt;In the London Tube experiment, the researchers place some of the blame on the “stylized nature” of the Tube map displayed to commuters. Its spatial distortions make it difficult to spot major inefficiencies in their route, without some external push. By comparison, we can usually estimate the impact of these “local” changes by ourselves. If we get off one stop earlier, maybe our walk to work increases by a minute but we avoid the wait at a crowded station. These slight changes are a bit like increasing just a single ingredient in a cookie.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;london_tube_map.jpg&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Personally, this describes my relationship with my own food. TO ADD MORE…&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;In my own life, I find this with food all the time. I have a set rotation of dishes I love, that fit my criteria (hassle-free ingredients, saves well for leftoers, etc). I’m happy to make small chaanes to what I eat. I recently realized how well a lone, unadorned sweet potato went with some of my staples. That’s a one step addition, and I can evaluate its impact as I walk the aisles of the store. Sure enough, it quickly became a staple.&lt;/li&gt;
&lt;li&gt;However, I’m sure there are many full dishes out there that would be just as good as my current rotation. But to find a new dish is a risk. There’s no way for me to see all the the links in the chain. Will the ingredients be easy to find? Will I find the cooking burdensome? What will the end result taste like? Are my cooking supplies well suited to the task?&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- * We provide some new rules of the game. We know not only the value at these points, we know the shape/slope/etc of the area around it. This is a reasonable relaxation, because we can estimate this shape by querying our computer for the values of the areas near our point (are we going up or down). The rule is that we can&#39;t look far away to see where the peak is (perhaps we&#39;re stuck in the Appalachian forests, and not the sheer granite of the Sierra Nevada).  --&gt;
&lt;!-- * This isn&#39;t arbitrary, it&#39;s a natural understanding of how we actually operate. We are inherently *local* optimizers. We can easily assess the impact of small changes, not not large ones. --&gt;
&lt;!-- * On a morning commute, we can estimate whether taking a turn a few blocks early to avoid a stoplight saves us time. It&#39;s much harder to figure out in advance whether taking the bus or train is easy. --&gt;
&lt;!-- * Now, I&#39;d wager that generally, we&#39;re rather good at making small (later, we will call these &#34;local&#34;, due to their geometric interpretation) adjustments. If I realize that by taking a right a few blocks early, I can avoid the long traffic light, I&#39;ll often do it.  --&gt;
&lt;!-- * However, there&#39;s a reason these are small changes. We can estimate their impact from where we are. If we considered an entirely new route to work, taking a whole different train line, we would have no way to know what that&#39;s like. --&gt;
&lt;p&gt;Before, we imagined a challenge where we tried to find a peak of a mountain range, using a computer which could tell us the elevation of any chosen input point. Let’s imagine that it also tells us the slope of the incline at that point (“which direction is down”). This better reflects our intuition for local optimization, but it’s also not a large change to the game, because we could always simply query the elevation in a small area around our point, and gauge the slope ourselves. Imagine that we are hiking with an altimeter, and we can look around us and see the shape of the nearby slope. However, we can’t just look around and find a faraway peak, because we’re stuck in the forests of the Appalachians rather than the sheer granite ofthe Sierra Nevada. Our intuition tells us the optimization algorithm which is natural: from wherever we are, “go up”.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;gradient-ascent&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Gradient Ascent&lt;/h1&gt;
&lt;p&gt;This intuitive is called “gradient ascent”. Wherever you are, go up. This is quite literal in the case of our mountain range, This section will provide its mathematical definition, but these details aren’t important, and you can skip the notation and go straight to the visualizations if you’d like. We begin with the intuitive description, and below write the algorithm out mathematically.&lt;/p&gt;
&lt;p&gt;In a bit more detail, we begin at some initial point. We find the direction of steepest ascent from that point, i.e. up the hill (the magnitude and direction of steepest ascent form the “gradient” vector). Then, we walk for a period in that direction (the amount is determined by the “step size”, and how steep the ascent actually is). Once we finish walking, we are at a new point, and we repeat this process again (we determine direction of steepest ascent, and walk in that direction). Once we reach a point that is essentially flat, there is no more direction of steepest ascent to follow, and we are done (this is called “convergence”).&lt;/p&gt;
&lt;p&gt;This is the intuitive definition of what it means to make &lt;em&gt;local&lt;/em&gt; changes. Wherever we are, we think “what small change could we make to make this better?” If our cookies are too salty, we add a bit less salt, but we don’t start over from scratch.&lt;/p&gt;
&lt;div id=&#34;mathematical-definition&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Mathematical Definition&lt;/h2&gt;
&lt;!-- Some explanation of continuous vs discrete space would be nice? --&gt;
&lt;p&gt;Imagine we are at some point &lt;span class=&#34;math inline&#34;&gt;\(x \in \mathbb{R}^d\)&lt;/span&gt; (meaning, &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; is a point in &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt;-dimensional space).
(Maybe in English first?)&lt;/p&gt;
&lt;p&gt;Here’s a mathematical definition of a crude version of gradient descent.&lt;a href=&#34;#fn6&#34; class=&#34;footnote-ref&#34; id=&#34;fnref6&#34;&gt;&lt;sup&gt;6&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Let &lt;span class=&#34;math inline&#34;&gt;\(f: \mathbb{R}^d \to \mathbb{R}\)&lt;/span&gt; be our objective function. Let &lt;span class=&#34;math inline&#34;&gt;\(\eta &amp;gt; 0\)&lt;/span&gt; be our scaling constant. We begin at some initial point &lt;span class=&#34;math inline&#34;&gt;\(x^{(0)} \in \mathbb{R}^d\)&lt;/span&gt;. For &lt;span class=&#34;math inline&#34;&gt;\(k = 0, \ldots,\)&lt;/span&gt;, until convergence, repeat steps 2 through 4(?).&lt;/li&gt;
&lt;li&gt;Compute the gradient &lt;span class=&#34;math inline&#34;&gt;\(\nabla f(x^{(k)})\)&lt;/span&gt;.&lt;/li&gt;
&lt;li&gt;Set &lt;span class=&#34;math inline&#34;&gt;\(x^{(k+1)} \leftarrow x^{(k)} + \eta \nabla f(x^{(k)})\)&lt;/span&gt;.&lt;/li&gt;
&lt;li&gt;If &lt;span class=&#34;math inline&#34;&gt;\(\nabla f(x^{(k)})\)&lt;/span&gt; is sufficiently small, halt the algorithm, and select &lt;span class=&#34;math inline&#34;&gt;\(x^{(k+1)}\)&lt;/span&gt; as our optima. Otherwise, set &lt;span class=&#34;math inline&#34;&gt;\(k \leftarrow k+1\)&lt;/span&gt;, and repeat steps 2-4.&lt;/li&gt;
&lt;/ol&gt;
&lt;!-- http://timharford.com/2016/10/big-decision-ahead-just-roll-the-dice/ --&gt;
&lt;/div&gt;
&lt;div id=&#34;visualizing-gradient-ascent&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Visualizing Gradient Ascent&lt;/h2&gt;
&lt;p&gt;It’s one thing to say that we follow the direction of steepest ascent, but what does that actually look like in practice? Imagine we have to summit a hill. This one is perfectly round, for simplicitly, but pretend we don’t know that, we can only see the local area around us.
&lt;!-- Need to go through and do better labels/etc for all these visualizations!  --&gt;s
&lt;!-- (Show the unimodel 2d case ) --&gt;&lt;/p&gt;
&lt;p&gt;The following is a contour plot, like what you find on a topographical map.&lt;/p&gt;
&lt;p&gt;It might be more clear if we consider viewing the map at an angle (thanks to the &lt;code&gt;rayshader&lt;/code&gt; &lt;a href=&#34;https://www.tylermw.com/3d-ggplots-with-rayshader/&#34;&gt;package&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;uni_vis_3d.png&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Imagine we start at that red dot in the top right. We look around, and see that the direction of steepest ascent is down and to the right.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;eta.temp &amp;lt;- 30
grad.first.step &amp;lt;- GradBivarNormal(x.uni.init)
# Manually compute second step, for visualization
x.uni.2 &amp;lt;- x.uni.init + eta.temp*grad.first.step

g.uni + uni.first.point + 
  geom_segment(aes(x = x.uni.init[1], y = x.uni.init[1],
                   xend = x.uni.2[1], yend = x.uni.2[2]),
               col = &amp;quot;red&amp;quot;, size = .25,
               arrow = arrow(length = unit(.2, &amp;quot;cm&amp;quot;), type = &amp;quot;closed&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-05-27-local-optimization.en/index_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;CONSIDER ONE MORE STEP&lt;/p&gt;
&lt;p&gt;Or in 3D…&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;uni_vis_3d_step2.png&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Below, we can watch a gif of the algorithm in action. Sure enough, in this simple setting, we head right to the top. [rw]&lt;/p&gt;
&lt;!-- ```{r, include = FALSE} --&gt;
&lt;!-- g.uni &lt;- tb.uni %&gt;%  --&gt;
&lt;!--   ggplot(aes(x = x, y = y)) + --&gt;
&lt;!--   geom_tile(aes(fill = z)) + --&gt;
&lt;!--   geom_contour(aes(z = z), bins = 15, color = &#34;black&#34;) + --&gt;
&lt;!--   scale_fill_gradientn(&#34;z&#34;, colours = terrain.colors(10)) + --&gt;
&lt;!--   coord_fixed() --&gt;
&lt;!-- g.uni --&gt;
&lt;!-- ``` --&gt;
&lt;p&gt;&lt;img src=&#34;2d_uni_grad_ascent_anim.gif&#34; /&gt;
&lt;!-- THIS angle isn&#39;t very good, will have to adjust --&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;not-all-mountains-are-friendly&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Not All Mountains Are Friendly&lt;/h1&gt;
&lt;p&gt;In this simple example, our local minimization strategy (“just go up!”) finds the highest peak without any trouble. However, not all mountain ranges are quite so friendly. Imagine there were three different peaks, of differing heights. It’s a bit harder to picture, but there’s a 3D visualization after the contour plot to help.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Basic plot of the setup
g.mix &amp;lt;- tb.grid %&amp;gt;% 
  ggplot(aes(x = x, y = y)) +
  geom_tile(aes(fill = z)) +
  geom_contour(aes(z = z), bins = 15, color = &amp;quot;black&amp;quot;) +
  ylim(-7.5,7.5) + xlim(-7.5, 7.5)+
  scale_fill_gradientn(&amp;quot;z&amp;quot;, colours = terrain.colors(10)) +
  coord_fixed()
g.mix&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: Removed 17500 rows containing non-finite values (stat_contour).&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: Removed 17500 rows containing missing values (geom_tile).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-05-27-local-optimization.en/index_files/figure-html/unnamed-chunk-10-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;mix_vis_3d.png&#34; /&gt;&lt;/p&gt;
&lt;!-- * 3d view, to help get a sense of it. --&gt;
&lt;!-- ```{r, include = FALSE} --&gt;
&lt;!-- #par(mfrow = c(1, 2)) --&gt;
&lt;!-- # plot_gg(g, width = 7, height = 4, raytrace = FALSE, preview = TRUE) --&gt;
&lt;!-- # plot_gg(g, multicore = TRUE, raytrace = TRUE, width = 7, height = 4,  --&gt;
&lt;!-- #         scale = 300, windowsize = c(1400, 866),  --&gt;
&lt;!-- #         zoom = 0.6, phi = 30, theta = 30) --&gt;
&lt;!-- # plot_gg(g,  --&gt;
&lt;!-- #         raytrace = FALSE,  --&gt;
&lt;!-- #         preview = TRUE) --&gt;
&lt;!-- # plot_gg(g,  --&gt;
&lt;!-- #         multicore = TRUE,  --&gt;
&lt;!-- #         raytrace = TRUE, --&gt;
&lt;!-- #         zoom = 0.6,  --&gt;
&lt;!-- #         phi = 30,  --&gt;
&lt;!-- #         theta = 30) --&gt;
&lt;!-- # render_camera(zoom=0.5,theta=-30,phi=30) --&gt;
&lt;!-- # render_snapshot(clear = TRUE) --&gt;
&lt;!-- # Sys.sleep(0.2) --&gt;
&lt;!-- # render_snapshot(clear = TRUE) --&gt;
&lt;!-- ``` --&gt;
&lt;ul&gt;
&lt;li&gt;Animation, currently on 2d, to show how gradient ascent works&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;2d_mix_grad_ascent_anim.gif&#34; /&gt;&lt;/p&gt;
&lt;div id=&#34;the-perils-of-nonconvexity&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;The Perils of “Nonconvexity”&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Which optimization challenges are hard? Math draws a fairly simple distinction. &lt;a href=&#34;#fn7&#34; class=&#34;footnote-ref&#34; id=&#34;fnref7&#34;&gt;&lt;sup&gt;7&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;In short, in the convex realm, local information provides global guidance. The local slope is pointing us in a direction&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Description of convex vs non-convex optimization, why they are two fundamentally different challenges.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;embracing-random-noise&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Embracing Random Noise&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;The explanation of the noise step.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;sgd-and-neural-nets&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;SGD, and Neural Nets&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;We have seen randomization introduced quite literally, by a random movement. But randomization is often introduced less explicitly into popular algorithms.&lt;/li&gt;
&lt;li&gt;Neural networks are the much heralded staple of the rise of machine learning. Their optimization, perhaps consistent of millions or billions of dimensions (we considered a &lt;em&gt;single&lt;/em&gt; dimension for visualization purposes above)&lt;/li&gt;
&lt;li&gt;Microsoft boasted of a neural network with &lt;a href=&#34;https://www.microsoft.com/en-us/research/blog/zero-deepspeed-new-system-optimizations-enable-training-models-with-over-100-billion-parameters/&#34;&gt;17 billion(!)&lt;/a&gt; parameters, each of which are a dimension to be optimized.&lt;/li&gt;
&lt;li&gt;The result is an enormous amount of potential spurious optima.&lt;/li&gt;
&lt;li&gt;What we’ve found over the past decade, SGD works “unreasonably well”. It’s explicitly an algorithm for convex optimization, and yet it optimizes these deep networks.&lt;/li&gt;
&lt;li&gt;There are a variety of complex answers, depending on who you ask, but the staple reason which dates back &lt;a href=&#34;https://leon.bottou.org/publications/pdf/nimes-1991.pdf&#34;&gt;decades&lt;/a&gt; is that its inherent noisiness allows it to escape spurious local optima.&lt;a href=&#34;#fn8&#34; class=&#34;footnote-ref&#34; id=&#34;fnref8&#34;&gt;&lt;sup&gt;8&lt;/sup&gt;&lt;/a&gt; The noisiness comes not fro our explicit introduction, but from the its approximation error.&lt;/li&gt;
&lt;li&gt;The noise of SGD has little analogy in our own lives, but the way that noise becomes a tool, not a hindrance, in non-convex optimization, is very real.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;SGD is the staple way to optimize neural networks.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;simulated-annealingthe-other-random-optimization-approaches&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Simulated Annealing/the other random optimization approaches?&lt;/h1&gt;
&lt;/div&gt;
&lt;div id=&#34;wrapping-up&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Wrapping Up&lt;/h1&gt;
&lt;p&gt;Of course, this is &lt;em&gt;hard&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;A pointed self help message would say to fine and embrace randomness. But with no such agenda, I can say that’s true, but also incredibly hard to get right&lt;/p&gt;
&lt;p&gt;just look at the gif! this is all powerful theory, but hard to chose the right way to introduce noise. in a clean, mathematical scenario, we can study the sorts of noise that are optimal, without any cost. when it comes to our own personal life, we experience this noise as disruption.&lt;/p&gt;
&lt;p&gt;The famous computer scientist Alan Perlis said “Optimization hinders evolution”, and it’s true. This is the fundamental “explore vs exploit” trade-off. We could spend our energy searching for better strategies (“explore”), or we could focus on deriving the benefit from the currently known optimal strategy (“exploit”). In almost every application, there is a trade-off, and it’s very hard to get right. I think our status quo bias and inherently “local” perspective means we’ll typically err on the side of spending too little time exploring, but of course it’s hard to know how to do that.&lt;/p&gt;
&lt;p&gt;But the takeaway could be something as simple as welcoming disruption, rather than resisting it. There’s no point in getting mad at a change to your commute, the world won’t notice (cite quote?), but maybe you can use the simple platitude that this is the necessary phase of exploration.&lt;/p&gt;
&lt;p&gt;Scrambled eggs are a wonderful way to start my morning. I doubt there’s much more room to optimize the way I enjoy them. But I’d be foolish to think that there weren’t wildly different options that were just as rewarding. [rw]&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;test_grad_ascent_anim.gif&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;test_noisy_ascent_anim.gif&#34; /&gt;&lt;/p&gt;
&lt;!-- ```{r, include = FALSE} --&gt;
&lt;!-- # f &lt;- function(x) { --&gt;
&lt;!-- #   (-x^2 + 3*x -2)*(x^2 -.5*x + 6) --&gt;
&lt;!-- # } --&gt;
&lt;!-- # x.seq &lt;- seq(-10, 10, .1) --&gt;
&lt;!-- # plot(x.seq, f(x.seq)) --&gt;
&lt;!-- ``` --&gt;
&lt;/div&gt;
&lt;div id=&#34;sources&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Sources&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://timharford.com/books/messy/&#34;&gt;“Messy”&lt;/a&gt;, by Tim Harford.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://users.ox.ac.uk/~econ0360/FerdinandRauch/Tube.pdf&#34;&gt;“The Benefits of Forced Experimentation: Striking
Evidence from the London Underground Network”&lt;/a&gt;, by Larcom, Rauch, &amp;amp; Willems (2017).&lt;/li&gt;
&lt;li&gt;Short &lt;a href=&#34;http://cep.lse.ac.uk/pubs/download/cp455.pdf&#34;&gt;write-up&lt;/a&gt; of the London Tube Strike research.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/46507.pdf&#34;&gt;“Bayesian Optimization for a Better Dessert”&lt;/a&gt;, by Kochanski et al. (2017).&lt;/li&gt;
&lt;li&gt;The &lt;a href=&#34;https://www.rayshader.com/&#34;&gt;&lt;code&gt;rayshader&lt;/code&gt; package&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;Albeit, this seems much harder to rigorously prove, than to simply cite the study as a neat thought experiment, like I’m doing here.&lt;a href=&#34;#fnref1&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn2&#34;&gt;&lt;p&gt;I have no personal insight into the rigor of the experiment itself, it’s being used just as a framing device here.&lt;a href=&#34;#fnref2&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn3&#34;&gt;&lt;p&gt;A rare, and extremely tenuous connection between areas of my research, and reality.&lt;a href=&#34;#fnref3&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn4&#34;&gt;&lt;p&gt;Or you could add in other factors, like cost and pleasantness.&lt;a href=&#34;#fnref4&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn5&#34;&gt;&lt;p&gt;I’ve tasted the resulting cookies, not bad for a cafeteria batch.&lt;a href=&#34;#fnref5&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn6&#34;&gt;&lt;p&gt;This is for an extremely crude version with fixed step size &lt;span class=&#34;math inline&#34;&gt;\(\eta\)&lt;/span&gt;. There is no reason to use fixed step size in practice, but that adjustment isn’t relevant to the demonstration.&lt;a href=&#34;#fnref6&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn7&#34;&gt;&lt;p&gt;Like maximization and minimization, convex and concave will be used interchangeably. The multiplying a convex function by minus &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt; makes it concave. Concave functions are easy to maximize, but we can switch between the two interchangeably.&lt;a href=&#34;#fnref7&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn8&#34;&gt;&lt;p&gt;And “saddle points”, which I am skirting past here, as they are a similar concern for this high level explanation.&lt;a href=&#34;#fnref8&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>A Gentle Introduction to Parlays and Independence </title>
      <link>/post/parlays-independence/</link>
      <pubDate>Thu, 08 Nov 2018 00:00:00 +0000</pubDate>
      <guid>/post/parlays-independence/</guid>
      <description>&lt;blockquote&gt;
&lt;p&gt;Betting parlays of positively correlated events will generally be profitable.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This statement is far from revolutionary, and will be obvious to those familar with the fundamentals of betting. However, I&amp;rsquo;ve talked to many folks with no prior experience who wanted to learn more. I thought it would be interesting and fun to write up a basic tutorial in this concept which assumes minimal background in probability (and should provide good intuition even with no mathematical foundation). This post is intended as an exercise in explaining concepts at an introductory level, and should be ignored by those who are already comfortable with the tools of probability (although many might find the 2018 election parlay opportunities of interest).&lt;/p&gt;
&lt;h1 id=&#34;betting&#34;&gt;Betting&lt;/h1&gt;
&lt;p&gt;Most people are familiar with the concept of a bet. I might flip a coin, and the loser pays the winner a dollar, which feels like a fair deal. Implicit in our evaluation of this bet as &amp;ldquo;fair&amp;rdquo; is the concept of Expected Value (EV). While this will avoid the mathematical definition whenever possible, we tend to have an intuitive sense of EV when we confront it in our daily lives. The fact that the coin flipping game is &amp;ldquo;fair&amp;rdquo; is obvious due to its symmetry. But if I instead offered to roll a die, and said that on a one through four you pay me a dollar, and on a five or six I pay you two dollars, many people would intuitively see this bet as fair as well. I have twice the chance to win, but have to pay out twice as much. Mathematically, we simply find the sum of all the outcomes multiplied by their probability of occurrence. I have \(2/3\) chance to pay you a dollar, and \(1/3\) chance to win two dollars, and \(-1*\frac{2}{3} + 2*\frac{1}{3} = 0\).&lt;/p&gt;
&lt;p&gt;When it comes to betting, it&amp;rsquo;s worth noting that Expected Value is the &lt;em&gt;only&lt;/em&gt; viable way to consider the outcome, and any other metric is bound to be a losing strategy in the long run. That doesn&amp;rsquo;t mean it applies in every practical situation. If I offered you a deal where I would double your life&amp;rsquo;s savings with a 55% chance, and you would lose it all with 45% chance, this is clearly a positive expected value bet, and it is also one that you should demonstrably &lt;em&gt;never&lt;/em&gt; take. The marginal utility of money states that the value of doubling your life savings does not equate to the loss from losing your life&amp;rsquo;s savings. This is a reminder that betting is particularly problematic in any situation where the stakes are not so low that you can focus solely on EV. If someone offered you the same deal on each of your individual dollars in your life savings independently, then it would be a consistently profitable proposition with essentially no downside, due to the law of large numbers. (And if one&amp;rsquo;s life savings is not suitably large so that the law of large numbers applies, betting should be far from your mind). This is not the purpose of this summary, but for anyone who does plan to place bets, it is essential that they give some preliminary consideration to the marginal utility of money, bankroll management, and the law of large numbers.&lt;/p&gt;
&lt;h1 id=&#34;betting-notation&#34;&gt;Betting Notation&lt;/h1&gt;
&lt;p&gt;In America, bets are usually denoted using the Moneyline system, where odds are reported in the form of \(\pm X-[\)hundred]. A +\(200\) line says that if you bet \$100 and win, you receive back \$200 plus your original bet. A \(-250\) line says that if you bet \$250 and win, you win \$100 (and of course also win back your original bet). This system makes it intuitive to measure your payout on a specific bet, but it is somewhat opaque when newer bettors try and understand the corresponding probabilities associated with each bet. We can work in terms of &amp;ldquo;Implied Odds&amp;rdquo;, which are simply the corresponding percentage chance that you would need to win for the bet to be breakeven in expected value. A +200 Moneyline has corresponding Implied Odds of 33.3%. Abroad, odds are frequently reported in fractional terms, a +200 Moneyline corresponds to 2/1 (&amp;ldquo;two to one&amp;rdquo;) odds. We note that Moneyline odds will be in the form of plus or minus at least \(100\). American sports will also report bettling lines such as the New England Patriots being \(-7.5\) for their game. This is a &lt;em&gt;point spread&lt;/em&gt;, where there is even money to be made betting whether the Patriots will score at least \(7.5\) more points than their opponent. I personally find it nearly impossible to quickly understand Moneyline odds in terms of probabilities, so I built a light 
&lt;a href=&#34;https://chrome.google.com/webstore/detail/odds-converter/klechkhopfnjihobbcfeheooaigjjgdg&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Chrome extension&lt;/a&gt; that can quickly perform these conversions on the fly.&lt;/p&gt;
&lt;h1 id=&#34;parlays&#34;&gt;Parlays&lt;/h1&gt;
&lt;p&gt;Standard bets offer a payout based on a binary result. You might bet that the Golden State Warriors win the NBA title (&amp;ldquo;NBA Futures&amp;rdquo;), or that the Eagles score at least six more points than the Raiders in their upcoming game (&amp;ldquo;beating the spread&amp;rdquo;). A bettor who has fallen on hard times might have little to do for the whole weekend but watch sports, and could place separate bets that Alabama beats Oklahoma and that Clemson beats Notre Dame in the College Football Playoff. However, they could also &amp;ldquo;parlay&amp;rdquo; events, in which they &lt;em&gt;only&lt;/em&gt; get paid out if &lt;em&gt;both&lt;/em&gt; those events occur (if Clemson beats ND but Alabama loses, then they would receive nothing). This seems like a scam, but the allure is that under a parlay the payoffs are multiplicative, and much more lucrative than simply the sum of those individual payouts. This is alluring to many bettors because it promises large paydays. In the above example, Alabama and Clemson were both large favorites, at -555 and -440 respectively (i.e. you have to place a bet of \$555 or \$440 to win a prize of \$100 if you are correct). Parlays are appealing to bettors because we have poor intuition for the likelihood of a number of independent (explained below) very likely events &lt;em&gt;all&lt;/em&gt; occurring. This fallacy is ubiquitous. In college football, when halfway through the season, a dozen contenders are 6-0, analysts and fans tend to look at their upcoming schedule, see that they are favored in each of those six games, and tend to muse about the situation in which each of those individually likely events occurs. In politics, readers are perplexed when analysts predict that of some 100 house races that lean solidly to one side, there will very likely be &lt;em&gt;some&lt;/em&gt; number of shocking upsets, even if we don&amp;rsquo;t know which one. Our mind works by considering individual events. If I can&amp;rsquo;t tell you &lt;em&gt;which&lt;/em&gt; remaining football game your team is likely to lose, you may be accustomed to think that the most likely result is that you don&amp;rsquo;t lose a single one, even when that is an unlikely event (as shown by the fact that even the top contenders tend to lose a game by the end of the college football season).&lt;/p&gt;
&lt;p&gt;On the other hand, parlays are appealing to bookies because they encourage more betting, and bookies profit from the volume of bets placed. There is no &lt;em&gt;catch&lt;/em&gt; here, and the bookies give a fair price on a parlay. Instead of the Clemson &amp;amp; Alabama example, we consider one where the probabilities are intuitive, with an extremely boring bookie that allows you to bet on the results of die rolls with no rake (which is the tax they take as profit on any bet placed). In each case, you bet \$1. For Bet A, they toss two dice, and you win \$12 (including your bet) when they sum to at least 11. For Bet B, they toss a single die, and you win \$6 (including your bet) if they roll a six. Both these bets have an expected value of 0. For Bet A, this has a 1 in 12 chance of occuring, so if you have placed a \$1 bet, you have a 1 in 12 chance of winning \$12, which is fair (and the same for Bet B with a 1 in 6 chance).&lt;/p&gt;
&lt;p&gt;If you wanted to up the stakes and instead ask for a parlay on these events, you could significantly increase your possible payout. Bookies are perfectly fair when it comes to parlays. They set their own lines, and choose how much &amp;ldquo;rake&amp;rdquo; to take from the bets, but when it comes to parlays, bookies follow a simple formula which preserves the expected value of the payouts. They simply consider it the same as a single bet on the event where both happen, with that probability computed by multiplying the individual probabilities together. In the case above, a parlay of Bet A and Bet B would yield a whopping \$72 payout when it hits. This calculation is predicated on the idea that the probability that both A and B occur is the product of their individual probabilities, so \(1/6 * 1/12 = 1/72\). If we use the mathematical shorthand \(P(A)\) to denote &amp;ldquo;Probability of Bet A succeeding&amp;rdquo;, and \(P(A,B)\) for &amp;ldquo;probability of both Bet A and Bet B succeeding&amp;rdquo;, we write this as \(P(A)*P(B)=P(A,B)\). Those familiar with probability will note that this formula holds for any two events which are &lt;em&gt;independent&lt;/em&gt;, that is, where information about the result of one event tells us nothing about the result of the other.&lt;/p&gt;
&lt;p&gt;Independence is a mathematically defined concept, but we have an intuition for its meaning. If I ask you to guess the probability that a baby is born on a white Christmas (that is, on a December 25th where it snows), you would be foolish to take the probability that the baby is born on December 25th, and multiply it by the probability that it is snowing on any given day. It is significantly more likely that it snows on December 25th than the average day because it is in the middle of winter. The proper calculation would be to find the product of the probabilities that it is December 25th, and that it is snowing on any given December 25th (a conditional probability, whose  definition we sidestep here). Luckily, in the case of our dice rolling bookie, independence is pretty irrefutable. Assuming that the dice are fair and properly weighted, the results of the first pair of rolls have no effect on the outcome of some later rolls.&lt;/p&gt;
&lt;h1 id=&#34;parlays-of-dependent-events&#34;&gt;Parlays of Dependent Events&lt;/h1&gt;
&lt;p&gt;This prompts the question, how do parlays work when the events are not independent? The short answer is that bookies generally do not offer parlays on dependent events, and that parlaying events that are positively correlated (i.e. the chance of one occurring makes it more likely that the other occurs) is profitable for the bettor. Luckily, most bets offered by the bookie tend to be independent. The scores of football games on a given Sunday seem to have little relation to one another. The most common bets to show dependence in fact show a &lt;em&gt;negative&lt;/em&gt; correlation, when only one can occur. A parlay on NBA futures where both the Golden State Warriors and the Cleveland Cavaliers win the NBA title is clearly nonsensical (the fact that the probability of both occurring is 0 is a form of dependence).&lt;/p&gt;
&lt;p&gt;What happens if a bookie allows betting on positively correlated events? This is best demonstrated by example. We consider Bet A and Bet B again, but with a twist. Bet A remains the same, but now define Bet B to be whether the first die rolled &lt;em&gt;of those used for Bet A&lt;/em&gt; is a six (rather than rolling a new die. Clearly, the individual probabilities are the same. However, these events are no longer independent. Intuitively, the success of Bet B (so the first roll is a 6) greatly increases the chance that Bet A succeeds (although it does not guarantee it). More precisely, the probability that both Bet A and Bet B occur is simply 1/18, as there are two possible rolls that are valid ([6,5] and [6,6]). However, \(1/18 &amp;gt; 1/72 = 1/6*1/12\). Thus, if the bookie provided an \$18 payout on this parlay, it would be break even for the bettor. If they provided the $72 pay out prescribed by the standard parlay formula, a bettor would print money in the long run.&lt;/p&gt;
&lt;p&gt;Correlated events still have a &amp;ldquo;correct&amp;rdquo; and fair price (in the example above, it was the substantially reduced price of $18). However, this computation required knowledge of their exact correlation. This is straightforward when it comes to the rolling of two dice, but difficult when it comes to the complex real world bets that bookies profit from. We can intuitively guess that the Super Bowl prop bet &amp;ldquo;Tom Brady throws for two or more touchdowns&amp;rdquo; is likely correlated with the bet &amp;ldquo;The Patriots (his team) win the Super Bowl&amp;rdquo;. In the world where we know Brady had a prolific scoring night, his team&amp;rsquo;s chances of winning are much higher (having essentially &amp;ldquo;removed&amp;rdquo; all of the worlds in which the Patriots offense was shut out, many of which were losing scenarios). But it is very difficult to estimate precisely how correlated those events are.&lt;/p&gt;
&lt;p&gt;Bookies prefer the simple solution: they do not offer correlated parlays. You can bet separately on these events, but they offer a singular pricing formula for parlays. Either the events are independent (in which case the probabilities are multicative, and they use their standard pricing formula), or they do not offer the parlay. In the world of sports, the divide between dependence and independence is usually fairly clear. Events in separate games on the same day should be independent. Events &lt;em&gt;within the same game&lt;/em&gt; tend not to be. There are correlations between a wide variety of events within the same game, even if it isn&amp;rsquo;t as obvious as &amp;ldquo;touchdowns scored&amp;rdquo; and &amp;ldquo;final result&amp;rdquo;. If a basketball team has twin stars, there will tend to be a slight negative correlation between their points scored, because there are a limited number of possessions and each shot taken by one player is a shot the other does not take. There are of course mitigating factors: a high scoring night for one player might indicate that the opposing defense is poor, or the two stars might both pass less to their supporting cast on nights when those role players are shooting poorly. But neither effect tends to outweigh the simple fact that there are a limited number of shots in the game. Bookies feel no obligation to attempt to set the correct price on these myriad combinations, and instead allow for parlays solely in the case of obviously plausible independence.&lt;/p&gt;
&lt;h1 id=&#34;parlays-in-political-elections&#34;&gt;Parlays in Political Elections&lt;/h1&gt;
&lt;p&gt;In practice, the statement &amp;ldquo;bookies do not allow for correlated parlays&amp;rdquo; is a sweeping generalization. Bookies make mistakes, and the &amp;ldquo;rake&amp;rdquo; that they take allows for a reasonable margin of error. It is better practice for them to consistently offer bets that attract bettors, than worry about the singular case in which they make a small mistake and suffer a loss. Bookies limit the amount that can be wagered at any given time, so even when they set an inaccurate line, they are not fleeced by sharp gamblers with deep pockets. It is always worth keeping an eye out for situations where bookies might slip up and offer such a profitable parlay.&lt;/p&gt;
&lt;p&gt;One such example came in the form of the 2018 midterm elections. Bookies offered bets on the results of individual races, general trends (&amp;ldquo;How many seats do Republicans gain in the Senate?&amp;quot;), and more. Some correlations are powerful and obvious. The result that Josh Hawley (Missouri), Dean Heller (Nevada), and Mike Braun (Indiana) win their Senate races is highly correlated with the GOP retaining control of the Senate. If they win those three close races, the odds that they somehow lose enough much more safe Senate seats for the Democrats to flip control is next to 0. I did not see any bookie foolish enough to allow parlays on these events. Generally, bookies are acutely aware that vertical structures like this (where one result is an aggregate of many individual results) have clear positive correlation.&lt;/p&gt;
&lt;p&gt;However, there was at least one bookie that allowed for parlays of &lt;em&gt;individual&lt;/em&gt; Senate races. For bookies accustomed to sports, this might seem sensible, as it is superficially similar to parlaying simultaneous game results. However, separate senate races can show obvious and consistent correlation. Some may dislike the language of this claim, as philisophically, it depends on your probabilistic interpretatin of a political race. It&amp;rsquo;s hard to see the connection between the senate choice of individual voters in Arizona and Nevada. However, under that framework, it&amp;rsquo;s hard to see how random chance enters the equation at all (voters are not flipping a coin at the ballot box, by and large). This ties into a deeper issue of how we interpret probabilistic forecasts, but my short answer would be that we use probability describe level of uncertainty about complex phenomena.&lt;/p&gt;
&lt;p&gt;Polling is the base staple of an election prediction. Even in the fantastical world where polls represent a perfectly random sampling of the entire voting population, there is the uncertainty that stems from the inherent randomness of such a random sample (luckily, this form of uncertainty is easy to mathematically model, and disappears as our sample gets very large). Then there is the uncertainty comes from the practical realities of imperfect polling, which crudely violates the simple assumptions taught in an introductory probability class (consider the work 538 does to grade pollsters as part of this uncertainty). And the final nebulous level of uncertainty comes from translating the results of the poll (which studies on a specific date who people say they plan to vote for) to the results of the election itself (determined by the choice of people who actually place a vote). These are two separate questions, and even if a poll precisely answers its own question, the translation of that to answer the second question can be clouded by the uncertainty of news that breaks after the poll is conducted, or voters who think it over some more and get cold feet, or a storm which prevents those without a car from making their way to the polling station, or any number of ways that these questions can differ. Election models have to grapple with these layers of uncertainty, and as a result a site like 538 reports that Ted Cruz has a &amp;ldquo;7 in 9&amp;rdquo; chance to beat Beto O&amp;rsquo;Rourke, and not complete certainty.&lt;/p&gt;
&lt;p&gt;The claim that election results are correlated fits neatly into this framework. It&amp;rsquo;s hard to define the connection between the individual decisions of voters in two states about two different pairs of candidates. But it&amp;rsquo;s easy to see how the errors in the probabilitic forecast would be connected. This is particularly true in the heavily partisan landscape of our current political system. The senate races in Nevada and Arizona aren&amp;rsquo;t entirely separate. In each of these demographically similar states, the populace is choosing between a democrat and a republican. Thus, certain forecasting errors made in one state tend to be mirrored in the other. The mistakes that pollsers make which could underestimate latino turnout will cause a similar divergence from the election forecasts and the final result in the two states.&lt;/p&gt;
&lt;p&gt;This implies that even in a world where the election outcomes are random according to the exact probabilities prescribed by the betting markets, a parlay offers a chance for profit. The positive correlation of these two results simply needs to outweigh the cost of the rake on these bets for these bets to have a positive expected value.&lt;/p&gt;
&lt;p&gt;We can illustrate this with the example of the bets I placed on the 2018 midterms. A significantly more complex and involved strategy could be used to profit from this parlaying opportunity, but this was just a fun example of the concept in practice.&lt;/p&gt;
&lt;h1 id=&#34;post-incomplete&#34;&gt;POST INCOMPLETE&lt;/h1&gt;
&lt;p&gt;To be continued&amp;hellip;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Scraping the &#34;Intelligence Squared&#34; Debate Results</title>
      <link>/post/scraping-is2/</link>
      <pubDate>Thu, 26 Jul 2018 00:00:00 +0000</pubDate>
      <guid>/post/scraping-is2/</guid>
      <description>&lt;p&gt;This is a brief companion to the 
&lt;a href=&#34;https://dylanpotteroconnell.github.io/debatefinalsummary/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;post&lt;/a&gt; analyzing the methods of assigning a winner to a debate, using the Intelligence Squared dataset. I will briefly outline here how I assemble that dataset, for trasparency.&lt;/p&gt;
&lt;h3 id=&#34;compiling-the-pages&#34;&gt;Compiling the Pages&lt;/h3&gt;
&lt;p&gt;The results from each Intelligence Squared debate are posted online in pages such as 
&lt;a href=&#34;https://www.intelligencesquaredus.org/debates/globalization-has-undermined-americas-working-class&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;this&lt;/a&gt;, including video of the debate, a description of the major positions of each side, the qualifications of the debaters, and most importantly, the results of the audience polling. Unfortunately, there doesn’t seem to be a central hub page that neatly lists all the URLs. However, the desired dataset isn’t huge (about 90 total debates), so there’s no substitute for the occasional work simply manually trawling through the website, and recording the date, name, and URL of each debate in question.&lt;/p&gt;
&lt;h3 id=&#34;scraping-the-numbers&#34;&gt;Scraping the numbers&lt;/h3&gt;
&lt;p&gt;Once we have a full list of all the relevant URLs, luckily, the results themselves are generally presented in a consistent format. Thus,  some simple work with regular expressions gathers the data that we need. One such example.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;debate_vote_results={&amp;quot;live&amp;quot;:{&amp;quot;pre&amp;quot;:{&amp;quot;f&amp;quot;:36,&amp;quot;a&amp;quot;:45,&amp;quot;u&amp;quot;:19,&amp;quot;w&amp;quot;:&amp;quot;a&amp;quot;},&amp;quot;post&amp;quot;:{&amp;quot;f&amp;quot;:32,&amp;quot;a&amp;quot;:61,&amp;quot;u&amp;quot;:7,&amp;quot;w&amp;quot;:&amp;quot;a&amp;quot;},&amp;quot;s&amp;quot;:41,&amp;quot;t&amp;quot;:100,&amp;quot;f&amp;quot;:{&amp;quot;f&amp;quot;:18,&amp;quot;a&amp;quot;:15,&amp;quot;u&amp;quot;:3},&amp;quot;a&amp;quot;:{&amp;quot;f&amp;quot;:6,&amp;quot;a&amp;quot;:38,&amp;quot;u&amp;quot;:1},&amp;quot;u&amp;quot;:{&amp;quot;f&amp;quot;:8,&amp;quot;a&amp;quot;:8,&amp;quot;u&amp;quot;:3}},&amp;quot;online&amp;quot;:{&amp;quot;t&amp;quot;:100,&amp;quot;pre&amp;quot;:{&amp;quot;f&amp;quot;:50,&amp;quot;a&amp;quot;:35,&amp;quot;u&amp;quot;:15,&amp;quot;w&amp;quot;:&amp;quot;&amp;quot;},&amp;quot;post&amp;quot;:{&amp;quot;f&amp;quot;:44,&amp;quot;a&amp;quot;:50,&amp;quot;u&amp;quot;:6,&amp;quot;w&amp;quot;:&amp;quot;&amp;quot;},&amp;quot;f&amp;quot;:{&amp;quot;f&amp;quot;:35,&amp;quot;a&amp;quot;:13,&amp;quot;u&amp;quot;:2},&amp;quot;a&amp;quot;:{&amp;quot;f&amp;quot;:4,&amp;quot;a&amp;quot;:27,&amp;quot;u&amp;quot;:4},&amp;quot;u&amp;quot;:{&amp;quot;f&amp;quot;:6,&amp;quot;a&amp;quot;:10,&amp;quot;u&amp;quot;:0}}};
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In case anyone wants to borrow this sort of simple scrape for their own projects, you can find the code 
&lt;a href=&#34;https://github.com/dylanpotteroconnell/IntelSquaredProject/blob/master/intelsquareddata.R&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;, although the approach is extremely messy. Luckily, with R it’s more important to be fast than it is to be clean, and you can use very awkward code as long as you find it readable and clear. Regular expressions like this can grab the relevant numbers that we need, and we store it in one large data frame.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-R&#34;&gt;gsub(&amp;quot;.*\&amp;quot;f\&amp;quot;:\\{\&amp;quot;f\&amp;quot;:(\\d+\\.*\\d*),\&amp;quot;a\&amp;quot;:(\\d+\\.*\\d*),\&amp;quot;u\&amp;quot;:(\\d+\\.*\\d*).*&amp;quot;, &amp;quot;\\1 \\2 \\3&amp;quot;, post)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;where we identify the numbers that we’re interested in. With the numbers compiled into one large data frame (which can be viewed in raw form 
&lt;a href=&#34;https://github.com/dylanpotteroconnell/IntelSquaredProject/blob/master/votingresultsfinal.csv&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;, for those interested in examining the data themselves). In total, there are 88 debates stretching back to 2012 which have all the information needed. The program itself stretches back further, but they only began tracking the subgroup movements more recently.&lt;/p&gt;
&lt;p&gt;In the next post, we can actually dive into the data itself.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
